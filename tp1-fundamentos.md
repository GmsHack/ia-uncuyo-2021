# Fundamentos filosóficos

Antes de que existieran las computadoras los filósofos ya se cuestionaban preguntas relacionadas a la Inteligencia Artificial, por ejemplo: ¿Cómo trabaja la mente? ¿Es posible que las máquinas actúen de forma inteligente, igual que las personas? Y si así fuera, ¿tendrían mentes? ¿Cuáles son las implicaciones éticas de las máquinas inteligentes?

Los filósofos han planteado dos enfoques de la Inteligencia Artificial: la **IA débil** y la **IA fuerte**.

La hipótesis de la IA débil plantea la posibilidad de que las máquinas se comporten como si fueran inteligentes. Mientras que la hipótesis de la IA fuerte hace referencia a que las máquinas piensan como si tuvieran mentes reales.

## Inteligencia Artificial Débil

*¿Pueden las máquinas actuar con inteligencia?*

Algunos filósofos han intentado demostrar que la IA es imposible; esto dependerá de cómo se la defina.

Si la definimos como la búsqueda del mejor programa agente en una arquitectura dada, entonces la IA resulta posible por definición, ya que es posible resolver el problema de encontrar un buen agente, dependiendo de la arquitectura. Sin embargo, los filósofos están interesados en el problema de comparar dos arquitecturas, la humana y la de la máquina. Ellos han formulado la pregunta de la siguiente manera: **«¿Pueden pensar las máquinas?»** y esta cuestión no está determinada, ya que la palabra pensar no tiene un significado bien definido.

Alan Turing rechazó la cuestión «¿Pueden pensar las máquinas?», y lo sustituyó por un **test de comportamiento**. Pocos investigadores en IA prestan atención al Test de Turing, y prefieren concentrarse en el rendimiento de sus sistemas en base a tareas prácticas, en vez de la habilidad de imitar a los humanos.

Turing también examinó una gran gama de posibles objeciones ante la posibilidad de las máquinas inteligentes, entre ellas: _el argumento de incapacidad, la objeción matemática y el argumento de la informalidad_.

El **argumento de incapacidad** afirma que una máquina nunca puede hacer X. Si bien es evidente que hay muchas tareas que las máquinas realizan igual o mejor que los humanos, todavía hay una gran cantidad de tareas en donde las computadoras no sobresalen.

La **objeción matemática** afirma que hay ciertas cuestiones matemáticas, que en principio, no pueden ser respondidas por sistemas formales concretos. Filósofos han afirmado que el teorema de incompletitud de Gödel demuestra que las máquinas son mentalmente inferiores a los hombres, porque las máquinas son sistemas formales limitados por este teorema, es decir, no pueden establecer la verdad de su propia sentencia.

Por último, el **argumento de la informalidad** afirma que el comportamiento humano es demasiado complejo para poder captarse mediante un simple juego de reglas y que debido a que los computadores no pueden nada más que seguir un conjunto de reglas, no pueden generar un comportamiento tan inteligente como el de los hombres.

## Inteligencia Artificial Fuerte

*¿Pueden las máquinas pensar de verdad?*

Muchos filósofos han afirmado que una máquina que pasa el Test de Turing no quiere decir que esté _realmente pensando_, sería solamente una *simulación* de la acción de pensar.

El Profesor Geoffrey Jefferson dice (1949):

> "Hasta que una máquina pueda escribir un soneto o componer un concierto porque sienta los pensamientos y las emociones, y no porque haya una lluvia de símbolos, podría reconocer que la máquina iguala al cerebro, es decir, no sólo escribirlo, sino que sepa que lo ha hecho."


Turing previó esta objeción y la llamó el argumento de la **consciencia**, donde la máquina tiene que ser consciente de sus propias acciones y estados mentales. Aunque la consciencia sea un tema importante, el punto de vista clave de Jefferson se relaciona realmente con la **fenomenología**, o el estudio de la experiencia directa, es decir, la máquina tiene que sentir emociones realmente. Otros se centran en la **intencionalidad**, esto es, en la cuestión de si las creencias, deseos y otras representaciones supuestas de la máquina son de verdad algo que pertenece al mundo real.

La respuesta de Turing a esta objeción es interesante. Mantiene que la cuestión de si las máquinas pueden pensar no está bien definida y plantea lo siguiente: 

> “¿Por qué deberíamos insistir en un estándar más alto para las máquinas que el usado para los humanos? Después de todo, en la vida ordinaria no tenemos nunca una evidencia directa sobre los estados mentales internos de otras personas. En vez de argumentar constantemente sobre este punto de vista, _es usual mantener la convención educada  de que todos pensamos_.”

Turing argumenta que Jefferson estaría dispuesto a ampliar la convención educada a las maquinas si al menos tuviera experiencia con las que actúan de forma inteligente. Reconoce que la cuestión de la conciencia es difícil, pero niega que sea relevante para la práctica de la IA.

Nos interesa crear programas que se comporten de forma inteligente y no en si alguien los declara reales o simulados. Por otro lado, muchos filósofos están especialmente interesados en esta cuestión y plantean distintas teorías sobre los estados y los procesos mentales.

Por un lado, la **teoría del funcionalismo** dice que un estado mental es cualquier condición causal inmediata entre la entrada y la salida. Bajo esta teoría, dos sistemas con procesos causales isomórficos tendrían los mismos estados mentales.

Mientras que la **teoría del naturalismo biológico** plantea que los estados mentales son características emergentes de alto nivel causadas por procesos neurológicos de bajo nivel en las neuronas, cuyas propiedades son las que importan.

Para investigar estos dos puntos de vista se examina _el problema de la mente-cuerpo_ y tres experimentos: _el del cerebro en una cubeta, el de la prótesis cerebral y el de la habitación china._

El **problema mente-cuerpo** cuestiona cómo se relacionan los estados y los procesos mentales con los estados y los procesos (específicamente del cerebro) del cuerpo.

El **experimento del cerebro en una cubeta** consiste en imaginar que se le extrae el cerebro a un niño recién nacido y se lo coloca en una cubeta donde se mantiene vivo y creciendo. Este cerebro recibe señales electrónicas de un simulador informático que pertenece a un mundo ficticio. La pregunta que se realiza es si serían los mismos los estados mentales de ese cerebro si estuviera alojado en el cráneo y creciendo de forma natural.

El **experimento de la prótesis cerebral** consiste en sustituir gradualmente todas las neuronas del cerebro por circuitos y, un tiempo después, invertir el proceso para retornar al sujeto a su estado biológico normal (teniendo en cuenta una serie de suposiciones previas). La pregunta es: ¿Qué pasaría con el sujeto objeto del experimento?

Por último, el **experimento de la habitación china** consiste en que en una habitación cerrada con una ventanilla de “entrada” y otra de “salida” hay una persona que solo entiende inglés, con un libro de reglas, un lápiz y varias hojas de papel. Por la ventana de entrada se introducen hojas con textos escritos en chino, la persona consulta su libro, hace sus anotaciones y al cabo de un rato coloca las hojas con el texto correspondiente en la ventana de salida. La persona no entiende chino, por lo que según Searle (quién describe el experimento como un sistema hipotético donde el humano es la CPU, el libro es el programa y los papeles son la memoria): “ejecutar el programa adecuado no genera necesariamente entendimiento”. Sin embargo, otros comentaristas como Mc Carthy argumentan que aunque la persona no entiende chino, el sistema se comporta como si lo entendiese. La pregunta a realizar en este experimento es si podemos realmente decir que la habitación china es una mente.

Los argumentos a favor y en contra de la IA fuerte no son concluyentes. Unos pocos investigadores dominantes en la disciplina de la IA creen que cualquier cosa significativa gira en torno al resultado del debate.

## La ética y los riesgos de desarrollar Inteligencia Artificial

Además de tener en cuenta en si es posible desarrollar IA, es importante pensar si se debería hacer. Es responsabilidad moral de los trabajadores en el campo redirigir la investigación si ven que los efectos de la tecnología de la IA son más negativos que positivos.

Muchas tecnologías han tenido efectos negativos no intencionados y la IA podría ser una de ellas. Algunos de los problemas que podría traer son:

 - Las personas podrían perder sus trabajos por la automatización. 
 - Las personas podrían tener demasiado (o muy poco) tiempo de ocio.
 - Las personas podrían perder el sentido de ser únicos.
 - Las personas podrían perder algunos de sus derechos privados.
 - La utilización de los sistemas de IA podría llevar a la pérdida de responsabilidad.
 - El éxito de la IA podría significar el fin de la raza humana.

Se han identificado distintas amenazas para la sociedad que se exponen tanto ante la IA como ante una tecnología relacionada.

Podemos concluir diciendo que algunas amenazas son improbables, pero merece la pena revisar dos de ellas en particular. La primera es que las máquinas ultra inteligentes podrían llevarnos a un futuro muy diferente del actual y puede que no sea de nuestro agrado. La segunda es que la tecnología de la robótica puede permitir a individuos con una psicopatía emplear armas de destrucción masiva. Concluimos diciendo que esto es más una amenaza de la biotecnología y nanotecnología que de la robótica.

![](https://embed.creately.com/JwF3WDJYCNl?token=QEU8Tr8Hy7suF4iy&type=svg%22%3E)

## Opinión personal

En mi opinión las máquinas si pueden “actuar” con inteligencia, de hecho, la inteligencia artificial débil ya existe, consiste en agentes que están orientados a problemas concretos, pero que no tienen una mente, estados mentales o una conciencia, simplemente actúan en base a como fueron programados e intentan resolver los problemas de la mejor manera posible.

Por el contrario, no diría que las máquinas pueden “pensar”, ya que asocio la palabra pensar a un estado mental propio de los seres humanos. Sí es cierto que hay cada vez más cosas en las que las máquinas “superan” a los humanos, pero no debemos olvidarnos que esas máquinas fueron programadas por los mismos y de no ser así, nunca podrían superarnos.

No creo que la inteligencia artificial fuerte sea posible, entendiéndola como la capacidad de las máquinas de contar con cualidades humanas como tener conciencia, mente, pensar o sentir emociones, aunque hay tantos avances tecnológicos y científicos que no lo puedo decir con seguridad.

Por último, creo que la inteligencia artificial trae muchísimos beneficios y no viene a reemplazar al ser humano sino a acompañarlo y ayudarlo en las cosas que no puede hacer. Todas las tecnologías pueden traernos beneficios siempre y cuando las usemos de manera correcta, depende de nosotros ser víctimas de nuestros propios inventos o utilizarlos para mejorar el mundo.